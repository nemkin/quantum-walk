\section{Classical random walks}

A classical random walk describe a stohastic process.

\unsure{The sequence can also be regarded as a special category of Markov chain ->Homogenous?}

Classical random walks on graphs can be defined using Markov-chains. Markov-chains
are well explained in Leo Breiman's book on Probability\cite{breiman_probability_1992} and Feng Xia, Senior Member, IEEE, Jiaying Liu, Hansong Nie, Yonghao Fu, Liangtian Wan, Member, IEEE,
Xiangjie Kong, Senior Member, IEEE - Random Walks: A Review of Algorithms and Applications, from IEEE Transactions on emerging topics in computational intelligence, on May 2019.

(Információelmélet előadás / a könyvet be lehetne idézni, bár kevésbé szeretik)

\definition{\textbf{Markov-chain}} (First order, discrete-time, discrete-space) A Markov-chain is a sequence of independent random variables from the same distribution, $X_1, X_2, X_3, \dots$, (with value set $A$), that have the Markov property:

\unsure{Hogy kellene az értékkészletet ($A$) jelölni?}

$P(X_k = x_k | X_{k-1} = x_{k-1}, \dots, X_1 = x_1) = P(X_k = x_k | X_{k-1} = x_{k-1})$

$\forall k\geq{}2$ and $x_{1},\dots, x{k}$ from the value set.

\definition{\textbf{Homogenous Markov-chain}} Time invariant, i.e.:
$P(\Phi_k = i | \Phi_{k-1} = j) = p_{j,i}$ $\forall k\geq{}2$, $\forall i,j \in{} A$, which is called the transition probability from $i$ to $j$ and form the transition probability matrix $P$.

This allows us to represent Homogenous Markov-chains as directed graphs.

\definition{\textbf{Distribution of the Markov-chain}} at the $i$th step, the Markov-chain's distribution is the distribution of $X_i$, which is $P(X_i = j)$.

\definition{\textbf{Stacionary distribution}} of the Markov chain is $p_{j} = \lim\limits_{i \to \infty} P(X_i = j)$.

\definition{\textbf{Graph representation of homogenous Markov-chains}}
Graph $G(V,E)$ represents a homogenous Markov-chain $X_1, X_2, X_3, \dots$, (with value set $A$ and transition probability matrix $P$), if $V=A$ and $E(i,j) = p_{j,i}$ $\forall{}i,j\in{}A$.

\definition{\textbf{Random walk on a graph}}
A random walk on this graph $G$ visits the nodes represented by the Markov-chain: $X_1, X_2, X_3, \dots$.

